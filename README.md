# Awesome-Instruction-Prompted-Vision
[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome) ![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fyeates%2Fawesome-instruction-prompted-vision&label=VISITOR&countColor=%23dce775&style=flat)

A curated list of instruction-prompted visual translation papers and resources, inspired by [awesome-image-inpainting](https://github.com/zengyh1900/Awesome-Image-Inpainting).

![](https://s2.loli.net/2023/12/05/HTrWELGOtlPwQCg.png)

<table>
  <tr>
    <td>
      <img src="assets/origin.gif" width="100%" />
      <br>
      <p>Original NeRF</p>
    </td>
    <td>
      <img src="assets/desert.gif" width="100%" />
      <br>
      <p>"Make it look like the Namibian desert"</p>
    </td>
    <td>
      <img src="assets/sunset.gif" width="100%" />
      <br>
      <p>"Make it sunset"</p>
    </td>
  </tr>
</table>


This `README.md` is automatically generated from [`awesome-list.csv`](awesome-list.csv). 

We provide [scripts](generate.py) to automatically generate `README.md` from CSV file or vice versa. 

Welcome to pull request to update or correct this collection.
## Image
- **arXiv** (2024) [High-Quality Image Restoration Following Human Instructions](https://arxiv.org/pdf/2401.16468.pdf). [![Star](https://img.shields.io/github/stars/mv-lab/InstructIR.svg?style=social&label=Star)](https://github.com/mv-lab/InstructIR)
- **arXiv** (2023) [MagicBrush: A Manually Annotated Dataset for Instruction-Guided Image Editing](https://arxiv.org/pdf/2306.10012.pdf). [![Star](https://img.shields.io/github/stars/OSU-NLP-Group/MagicBrush.svg?style=social&label=Star)](https://github.com/OSU-NLP-Group/MagicBrush) [![Website](https://img.shields.io/badge/Website-100)](https://osu-nlp-group.github.io/MagicBrush/) 
- **arXiv** (2023) [InstructDiffusion: A Generalist Modeling Interface for Vision Tasks](https://arxiv.org/pdf/2309.03895.pdf). [![Star](https://img.shields.io/github/stars/cientgu/InstructDiffusion.svg?style=social&label=Star)](https://github.com/cientgu/InstructDiffusion) [![Website](https://img.shields.io/badge/Website-100)](https://gengzigang.github.io/instructdiffusion.github.io/) 
- **arXiv** (2023) [Visual Instruction Inversion: Image Editing via Visual Prompting](https://arxiv.org/pdf/2307.14331.pdf). [![Star](https://img.shields.io/github/stars/thaoshibe/visii.svg?style=social&label=Star)](https://github.com/thaoshibe/visii) [![Website](https://img.shields.io/badge/Website-100)](https://thaoshibe.github.io/visii/) 
- **arXiv** (2023) [ImageBrush: Learning Visual In-Context Instructions for Exemplar-Based Image Manipulation](https://arxiv.org/pdf/2308.00906.pdf).
- **arXiv** (2023) [Inst-Inpaint: Instructing to Remove Objects with Diffusion Models](https://arxiv.org/pdf/2304.03246.pdf). [![Star](https://img.shields.io/github/stars/abyildirim/inst-inpaint.svg?style=social&label=Star)](https://github.com/abyildirim/inst-inpaint) [![Website](https://img.shields.io/badge/Website-100)](http://instinpaint.abyildirim.com/) 
- **arXiv** (2023) [Idea2Img: Iterative Self-Refinement with GPT-4V(ision) for Automatic Image Design and Generation](https://arxiv.org/pdf/2310.08541.pdf). [![Website](https://img.shields.io/badge/Website-100)](https://idea2img.github.io/) 
- **arXiv** (2023) [HIVE: Harnessing Human Feedback for Instructional Visual Editing](https://arxiv.org/pdf/2303.09618.pdf). [![Website](https://img.shields.io/badge/Website-100)](https://shugerdou.github.io/hive/) 
- **arXiv** (2023) [InstructSeq: Unifying Vision Tasks with Instruction-conditioned Multi-modal Sequence Generation](https://arxiv.org/pdf/2311.18835.pdf). [![Star](https://img.shields.io/github/stars/rongyaofang/InstructSeq.svg?style=social&label=Star)](https://github.com/rongyaofang/InstructSeq)
- **arXiv** (2023) [Emu Edit: Precise Image Editing via Recognition and Generation Tasks](https://arxiv.org/pdf/2311.10089.pdf). [![Website](https://img.shields.io/badge/Website-100)](https://emu-edit.metademolab.com/) 
- **ICLR** (2023) [InstructCV: Instruction-Tuned Text-to-Image Diffusion Models as Vision Generalists](https://arxiv.org/pdf/2310.00390.pdf). [![Star](https://img.shields.io/github/stars/AlaaLab/InstructCV.svg?style=social&label=Star)](https://github.com/AlaaLab/InstructCV)
- **ICLR** (2023) [Guiding Instruction-based Image Editing via Multimodal Large Language Models](https://arxiv.org/pdf/2309.17102.pdf). [![Star](https://img.shields.io/github/stars/apple/ml-mgie.svg?style=social&label=Star)](https://github.com/apple/ml-mgie) [![Website](https://img.shields.io/badge/Website-100)](https://mllm-ie.github.io/) 
- **CVPR** (2023) [InstructPix2Pix: Learning to Follow Image Editing Instructions](https://openaccess.thecvf.com/content/CVPR2023/papers/Brooks_InstructPix2Pix_Learning_To_Follow_Image_Editing_Instructions_CVPR_2023_paper.pdf). [![Star](https://img.shields.io/github/stars/timothybrooks/instruct-pix2pix.svg?style=social&label=Star)](https://github.com/timothybrooks/instruct-pix2pix) [![Website](https://img.shields.io/badge/Website-100)](https://www.timothybrooks.com/instruct-pix2pix/) 
## 3D
- **arXiv** (2024) [TIP-Editor: An Accurate 3D Editor Following Both Text-Prompts And Image-Prompts](https://arxiv.org/pdf/2401.14828.pdf).
- **arXiv** (2023) [InstructP2P: Learning to Edit 3D Point Clouds with Text Instructions](https://arxiv.org/pdf/2306.07154.pdf).
- **arXiv** (2023) [Instruct 3D-to-3D: Text Instruction Guided 3D-to-3D conversion](https://arxiv.org/pdf/2303.15780.pdf). [![Website](https://img.shields.io/badge/Website-100)](https://sony.github.io/Instruct3Dto3D-doc) 
- **arXiv** (2023) [InpaintNeRF360: Text-Guided 3D Inpainting on Unbounded Neural Radiance Fields](https://arxiv.org/pdf/2305.15094.pdf).
- **ICLR** (2023) [InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image](https://arxiv.org/pdf/2311.02826.pdf). [![Star](https://img.shields.io/github/stars/mybabyyh/InstructPix2NeRF.svg?style=social&label=Star)](https://github.com/mybabyyh/InstructPix2NeRF)
- **ICCV** (2023) [Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions](https://arxiv.org/pdf/2303.12789.pdf). [![Star](https://img.shields.io/github/stars/ayaanzhaque/instruct-nerf2nerf.svg?style=social&label=Star)](https://github.com/ayaanzhaque/instruct-nerf2nerf) [![Website](https://img.shields.io/badge/Website-100)](https://instruct-nerf2nerf.github.io/) 
## Video
- **arXiv** (2023) [Instruct-Video2Avatar: Video-to-Avatar Generation with Instructions](https://arxiv.org/pdf/2306.02903.pdf). [![Star](https://img.shields.io/github/stars/lsx0101/Instruct-Video2Avatar.svg?style=social&label=Star)](https://github.com/lsx0101/Instruct-Video2Avatar)
- **arXiv** (2023) [InstructVid2Vid: Controllable Video Editing with Natural Language Instructions](https://arxiv.org/pdf/2305.12328.pdf).
- **arXiv** (2023) [VIDiff: Translating Videos via Multi-Modal Instructions with Diffusion Models](https://arxiv.org/pdf/2311.18837.pdf). [![Star](https://img.shields.io/github/stars/ChenHsing/VIDiff.svg?style=social&label=Star)](https://github.com/ChenHsing/VIDiff) [![Website](https://img.shields.io/badge/Website-100)](https://chenhsing.github.io/VIDiff/) 
- **arXiv** (2023) [BIVDiff: A Training-free Framework for General-Purpose Video Synthesis via Bridging Image and Video Diffusion Models](https://arxiv.org/pdf/2312.02813.pdf). [![Star](https://img.shields.io/github/stars/bivdiff.github.io/.svg?style=social&label=Star)](https://bivdiff.github.io/)
- **arXiv** (2023) [Consistent Video-to-Video Transfer Using Synthetic Dataset](https://arxiv.org/pdf/2311.00213.pdf). [![Star](https://img.shields.io/github/stars/cplusx.github.io/InsV2V_project_page.svg?style=social&label=Star)](https://cplusx.github.io/InsV2V_project_page) [![Website](https://img.shields.io/badge/Website-100)](https://github.com/amazon-science/instruct-video-to-video/tree/main) 
## Multiple
- **arXiv** (2023) [Watch Your Steps: Local Image and Scene Editing by Text Instructions](https://arxiv.org/pdf/2308.08947.pdf). [![Website](https://img.shields.io/badge/Website-100)](https://ashmrz.github.io/WatchYourSteps/) 
